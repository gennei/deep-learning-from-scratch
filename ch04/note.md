# ニューラルネットワークの学習

## 4.5 学習アルゴリズムの実装

### STEP

1. ミニバッチ  
  訓練データからランダムサンプリングし、選ばれたデータをミニバッチと呼ぶとする。ミニバッチの損失感数の値を減らすことを目的とする

1. 勾配の算出  
  ミニバッチの損失関数を減らすために各重みパラメータの勾配を求める。勾配は損失感数の値を最も減らす方向を示す

1. パラメータの更新  
  重みパラメータを勾配方向に微小量だけ更新する。

1. 繰り返す  
  ステップ1, ステップ2, ステップ3, を繰り返す

上記を **確率的勾配降下法** と呼ぶ。頭文字をとって **SGD** と一般的に呼ばれる。
